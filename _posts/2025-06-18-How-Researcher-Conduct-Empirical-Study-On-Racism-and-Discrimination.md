Measuring attitudes like racism and discrimination is inherently difficult. These are **latent constructs**—internal beliefs and motivations that are **not directly observable**. People may also **hide or distort their true views** due to social pressure, making it harder to collect accurate data.

This post explains how researchers attempt to measure such sensitive topics, based on a large-scale study involving over 910,000 people.

## 📑 Table of Contents

1. [📝 Self-Report Scales](#1--self-report-scales)
2. [📝 Implicit Measures (IAT)](#2--implicit-measures-iat)
3. [📝 Scale Evaluation with IRT and CFA](#3--scale-evaluation-with-irt-and-cfa)
4. [📝 Nomological Network Analysis](#4--nomological-network-analysis)
5. [📝 Massive Data Sets](#5--massive-data-sets)
6. [📝 Limitations and Recommendations](#6--limitations-and-recommendations)
7. [📝 Interpreting the Figure on Racial Resentment](#7--interpreting-the-figure-on-racial-resentment)
   - [7.1 🧩 What it means](#71--what-it-means)
   - [7.2 🧩 Why it matters](#72--why-it-matters)
8. [📝 Reference](#8--reference)

---

## 1. 📝 Self-Report Scales

Most studies use **standardized questionnaires** to capture explicit attitudes. These are called **self-report scales**. Common examples include:

- *Modern Racism Scale*
- *Symbolic Racism 2000 Scale*
- *Social Dominance Orientation*

Participants respond to statements using a **Likert scale**, such as from “Strongly Disagree” to “Strongly Agree.”

**Example items:**
> “Racial minorities have received more than their fair share of economic resources.”  
> “I would be uncomfortable if a Black family moved in next door.”

Researchers score these responses to assess levels of explicit racial bias.

---

## 2. 📝 Implicit Measures (IAT)

To get around self-censorship, researchers often use **indirect tools** like the **Implicit Association Test (IAT)**.

This test measures how quickly people associate concepts like "good" or "bad" with different racial categories (e.g., White vs. Black faces).

The assumption is that **faster reaction times** for certain associations reflect **stronger unconscious biases**, even if someone denies being prejudiced.

---

## 3. 📝 Scale Evaluation with IRT and CFA

After data collection, researchers use advanced tools to assess **how well the scale works**.

- **Item Response Theory (IRT)** checks whether each question effectively distinguishes between low and high levels of racism.
- **Confirmatory Factor Analysis (CFA)** and **fit indices** (like RMSEA, CFI) evaluate whether all items consistently measure the same underlying trait.
- They also test for **floor or ceiling effects**—i.e., whether most participants score extremely low or high, making it hard to tell people apart.

---

## 4. 📝 Nomological Network Analysis

Researchers also study how racism scales correlate with other psychological traits. This is known as mapping a **nomological network**.

For example, if a racism scale correlates with political ideology, social conservatism, or empathy (as theory predicts), it likely measures a meaningful construct.

However, if multiple scales show **almost identical patterns**, they might not be capturing distinct dimensions of prejudice. Theoretical overlap is a major concern.

---

## 5. 📝 Massive Data Sets

The study referenced used **data from over 910,000 people**, likely gathered through:

- Online survey platforms (e.g., Project Implicit)
- University research pools
- Crowdsourcing platforms (e.g., MTurk, Prolific)

Large sample sizes help with statistical power, but they also **amplify issues with poor measurement**—flawed scales can yield misleading results on a large scale.

---

## 6. 📝 Limitations and Recommendations

- People may not report their true attitudes (social desirability bias).
- Some scales are **internally consistent** but fail to reflect the full range of beliefs.
- The field is **crowded with overlapping scales**, many of which need updating.

Researchers recommend both **careful selection** of validated instruments and **renovation** of older scales to ensure accuracy in the study of prejudice.

---

## 7. 📝 Interpreting the Figure on Racial Resentment

![Racial Resentment Figure](https://raw.githubusercontent.com/KehanLi-1123/KehanLi.github.io/master/images/racial_resentment.png)


The figure plots two key elements along the **Racial Resentment** continuum (x-axis):

1. **Purple area (primary y-axis, left):** This shows the **density distribution** of respondents' resentment scores. It resembles a bell curve centered around zero, indicating most people report moderate resentment, with fewer scoring very low or very high.

2. **Black line (secondary y-axis, right):** This is an **Item Information Curve**, derived from **Item Response Theory (IRT)**. It shows how much precision the scale achieves at different score levels.

### 7.1 🧩 What it means

- **Peak of the black curve at the left (around –4 to –2):** Indicates the scale is **most informative** (i.e., precise with lower resentment scores).
- **Flat or trough regions (around –1 to +2):** The scale provides **little information** here—meaning it can't reliably distinguish between respondents with mild to moderate resentment.
- **Rising again at the extremes:** Suggests better discrimination of **very high resentment**, but perhaps capturing few individuals in the sample.

Combined with the density plot:

- Many respondents occupy the **+0 to +2** region (central area), but **the scale is least precise there**.
- This indicates **poor measurement accuracy** precisely where many people fall—impairing the scale’s ability to detect meaningful differences among typical respondents.

---

### 7.2 🧩 Why it matters

- **Measurement precision is uneven**: The scale is "over-tuned" for very low or very high resentment and under-performs near average scores.
- **Floor and ceiling effects are present**, as mentioned in the article: respondents bunch near the mid‑range, where the instrument is least sensitive.
- For researchers, this suggests the scale might **miss subtle but theoretically important variation**, reducing its practical validity in many studies.

This kind of figure is a classic output of **IRT-based validation**, and aligns with the study’s broader findings that many scales have **adequate reliability but poor model fit** and **limited latent score precision**, especially across large samples, [Hester et al., 2023](https://link.springer.com/article/10.3758/s13428-022-01873-w).


## 8. 📝 Reference

> Hester, N., Axt, J. R., Siemers, N., Hehman, E. (2023). *Evaluating validity properties of 25 race-related scales*. *Behavior Research Methods*.  
[https://link.springer.com/article/10.3758/s13428-022-01873-w](https://link.springer.com/article/10.3758/s13428-022-01873-w)

